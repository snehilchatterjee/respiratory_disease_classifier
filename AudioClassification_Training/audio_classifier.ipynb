{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f12a315-5e97-4026-a985-0d1c9fca9971",
   "metadata": {},
   "source": [
    "### Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c861209b-b406-4ceb-88f0-c4cda64deae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "#Importing audio file paths\n",
    "import os\n",
    "\n",
    "#For managing dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#PyTorch\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "\n",
    "# Misc.\n",
    "import multiprocessing # will be used for loading data using multipler workers (cpu_count)\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Selecting device\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e9933-d394-4654-b4a6-c282b59dd9e5",
   "metadata": {},
   "source": [
    "### Recursively get all audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6a0daf-3d9d-4e91-ad47-f0e65286bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_fetch(src,audio_paths):\n",
    "    l=os.listdir(src)\n",
    "    if(len(l)!=0):\n",
    "        for i in range(len(l)):\n",
    "            if(\".wav\" in l[i] or \".mp3\" in l[i] or \".aac\" in l[i]):\n",
    "                audio_paths.append(str(src+l[i]))\n",
    "            elif(\".\" not in l[i]):\n",
    "                try:\n",
    "                    audio_fetch(str(src+\"/\"+l[i]+\"/\"),audio_paths)\n",
    "                except:\n",
    "                    continue\n",
    "                            \n",
    "# For getting all possible classes along with their label encoding as a dictionary\n",
    "def class_fetch(df: pd.DataFrame())->(list,dict):\n",
    "    s=set(sorted(df[1].unique()))\n",
    "    \n",
    "    toDel=[i for i in dict(df[1].value_counts(sort=True)).keys() if dict(df[1].value_counts(sort=True))[i]<3]\n",
    "    for i in toDel:\n",
    "        s.remove(i)\n",
    "    d={}\n",
    "    \n",
    "    toDel_ids=[]\n",
    "    for i in toDel:\n",
    "        toDel_ids.extend(list(df[df[1]==i][0].values))\n",
    "    \n",
    "    \n",
    "    count=0\n",
    "    for i in s:\n",
    "        d[i]=count\n",
    "        count+=1\n",
    "    return list(s),d, toDel_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2801d1-6044-40a8-aefa-74ab85dee3af",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c73728-c4cd-43b5-9208-2d3b649319f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class audio_dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 info: str,\n",
    "                 audio_path=None,\n",
    "                 audio_files=None,\n",
    "                 target_sample_rate=16000,\n",
    "                 num_samples=320000,\n",
    "                 transforms=None,\n",
    "                 header=None) -> None:\n",
    "        \n",
    "        self.paths=[]\n",
    "\n",
    "        if (audio_path==None and audio_files==None):\n",
    "            raise Exception(\"Both audio_path and audio_files cannot be None at the same time\")\n",
    "\n",
    "        if(audio_files==None):\n",
    "            audio_fetch(audio_path,self.paths)\n",
    "        else:\n",
    "            self.paths=audio_files\n",
    "\n",
    "        self.transformation=transforms\n",
    "        self.target_sample_rate=target_sample_rate\n",
    "        self.target_samples=num_samples\n",
    "        \n",
    "        self.patient=dict()\n",
    "        self.paths.sort() \n",
    "        \n",
    "        # We are going to remove all classes than 2 patient data\n",
    "\n",
    "        for i in self.paths:\n",
    "            index=int(i.split(\"/\")[-1].split(\"_\")[0])\n",
    "            self.patient[index]=[]\n",
    "        \n",
    "        for i in range(len(self.paths)):\n",
    "            self.patient[int(self.paths[i].split(\"/\")[-1].split(\"_\")[0])].append(self.paths[i])\n",
    "        \n",
    "        self.info_df=pd.read_csv(info,header=header)\n",
    "        self.classes, self.class_to_idx, self.ids_to_remove = class_fetch(self.info_df)\n",
    "\n",
    "        # After getting the patient ids to remove all the data from patient list is removed\n",
    "        for i in self.ids_to_remove:\n",
    "            if i in self.patient.keys():\n",
    "                self.patient.pop(i)\n",
    "\n",
    "        #Denotes sequence of audio files for a particular patient\n",
    "        self.sequence=list(self.patient.values())\n",
    "\n",
    "        # Audio path is updated after removing classing with small number of patients\n",
    "        self.paths=[]\n",
    "        for i in self.sequence:\n",
    "            if(i!=[]):\n",
    "                for j in i:\n",
    "                    self.paths.append(j)\n",
    "\n",
    "    \n",
    "    def get_class(self,file: str):\n",
    "        return self.info_df[self.info_df[0]==int(file.split(\"/\")[-1].split(\"_\")[0])][1].values[0]\n",
    "\n",
    "\n",
    "    # Necessary audio transformations: \n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.target_samples:\n",
    "            signal = signal[:, :self.target_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.target_samples:\n",
    "            num_missing_samples = self.target_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor():\n",
    "        self.val=self.paths[index]\n",
    "        self.class_val=self.class_to_idx[self.get_class(self.val)]\n",
    "\n",
    "        self.signal, self.sr = torchaudio.load(self.val)\n",
    "        self.signal = self._resample_if_necessary(self.signal, self.sr)\n",
    "        self.signal = self._mix_down_if_necessary(self.signal)\n",
    "        self.signal = self._cut_if_necessary(self.signal)\n",
    "        self.signal = self._right_pad_if_necessary(self.signal)\n",
    "        if(self.transformation!=None):\n",
    "            self.signal = self.transformation(self.signal)\n",
    "\n",
    "        return self.signal,self.class_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d69c53-099d-4872-8995-1a22f40b5ffb",
   "metadata": {},
   "source": [
    "##### Testing audio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee9fbf4-8673-444f-bf7d-37167d40138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pneumonia': 0,\n",
       " 'Healthy': 1,\n",
       " 'Bronchiolitis': 2,\n",
       " 'Bronchiectasis': 3,\n",
       " 'COPD': 4,\n",
       " 'URTI': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=16000,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=64\n",
    "    )\n",
    "\n",
    "ds=audio_dataset(audio_path=\"../Sound_Classification/archive/Respiratory_Sound_Database/\",info=\"../Sound_Classification/archive/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv\",transforms=mel_spectrogram)\n",
    "ds.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d59361e-6d17-4230-9894-30e277295574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "COPD\n"
     ]
    }
   ],
   "source": [
    "print(len(ds.sequence))\n",
    "print(ds.get_class(ds.paths[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad11d1-6b4a-47ed-a2b9-966513802e32",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffe44aa-4c99-48f3-b5be-7c4aebdefaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before trimming:\n",
      "No. of audio files in train_ds: 552\n",
      "No. of audio files in test_ds: 184\n",
      "No. of audio files in val_ds: 184\n",
      "\n",
      "After trimming:\n",
      "No. of audio files in train_ds: 550\n",
      "No. of audio files in test_ds: 183\n",
      "No. of audio files in val_ds: 184\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=4\n",
    "NUM_WORKERS=multiprocessing.cpu_count()\n",
    "\n",
    "ds=[]\n",
    "audio_fetch(\"../Sound_Classification/archive/respiratory_sound_database/\",ds)\n",
    "\n",
    "# Perform train test split\n",
    "train_ds,temp_ds=train_test_split(ds,test_size=0.4)\n",
    "test_ds,val_ds=train_test_split(temp_ds,test_size=0.5)\n",
    "\n",
    "print(f\"Before trimming:\")\n",
    "print(f\"No. of audio files in train_ds: {len(train_ds)}\\nNo. of audio files in test_ds: {len(test_ds)}\\nNo. of audio files in val_ds: {len(val_ds)}\")\n",
    "\n",
    "train_ds=audio_dataset(audio_files=train_ds,info=\"../Sound_Classification/archive/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv\",transforms=mel_spectrogram)\n",
    "test_ds=audio_dataset(audio_files=test_ds,info=\"../Sound_Classification/archive/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv\",transforms=mel_spectrogram)\n",
    "val_ds=audio_dataset(audio_files=val_ds,info=\"../Sound_Classification/archive/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv\",transforms=mel_spectrogram)\n",
    "\n",
    "print(f\"\\nAfter trimming:\")\n",
    "print(f\"No. of audio files in train_ds: {train_ds.__len__()}\\nNo. of audio files in test_ds: {test_ds.__len__()}\\nNo. of audio files in val_ds: {val_ds.__len__()}\")\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS)\n",
    "test_loader=torch.utils.data.DataLoader(test_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS)\n",
    "val_loader=torch.utils.data.DataLoader(val_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057acd7-5e6a-4e88-9759-502addf95d34",
   "metadata": {},
   "source": [
    "##### Checking dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae0cf7d-392b-4756-a4d9-5ba707bd553e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2657841724.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    x_axis='time')'''\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "im=next(iter(train_loader))[0][0]\n",
    "im=im.permute(1,2,0)\n",
    "\n",
    "librosa.display.specshow(librosa.power_to_db(y,ref=np.max),\n",
    "                             y_axis='mel',\n",
    "                             fmax=8000,\n",
    "                             x_axis='time')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.specgram(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aae5f5-c4d9-44a1-ac3a-36a017ed33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5de65-db6c-4004-a018-7a2a65b43835",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83bc18-b8f6-41e9-afb9-da5daa7d9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class auditory_transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_embedding=nn.Sequential(nn.BatchNorm1d(num_features=1),\n",
    "                                           nn.Conv1d(in_channels=1,out_channels=128,kernel_size=3),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.BatchNorm1d(num_features=128),\n",
    "                                           nn.Conv1d(in_channels=128,out_channels=256,kernel_size=3),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.BatchNorm1d(num_features=256),\n",
    "                                           nn.Conv1d(in_channels=256,out_channels=512,kernel_size=3),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.BatchNorm1d(num_features=512),\n",
    "                                           nn.Conv1d(in_channels=512,out_channels=1024,kernel_size=3),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.BatchNorm1d(num_features=1024),\n",
    "                                           nn.Conv1d(in_channels=1024,out_channels=2048,kernel_size=3),\n",
    "                                           nn.ReLU(),\n",
    "                                           nn.BatchNorm1d(num_features=2048),\n",
    "                                           nn.Conv1d(in_channels=2048,out_channels=4096,kernel_size=3))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.input_embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84ad23-c948-4730-9e56-55a6825b9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814e529-32c3-4470-b631-8227b0ee741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=auditory_transformer().to(device)\n",
    "with torch.inference_mode():\n",
    "    model((next(iter(train_loader))[0]).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a9def-1d49-4f91-a497-49eb1fd2a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv, sr=torchaudio.load(train_ds.paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2da0f-2d2e-4453-a790-05e9616dd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resmaple=torchaudio.transforms.Resample(torchaudio.load(train_ds.paths[0])[1],16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f184ef3-8336-459b-992c-611d39df4d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resmaple(wv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aaeabb-d74d-4735-a47a-727bd4f43975",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(next(iter(train_loader))[0].to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47175fc8-b624-4759-8d2c-50ecf6415fbd",
   "metadata": {},
   "source": [
    "### R & D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81c73eb4-5c87-4457-bce3-9337788dd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv, sr=librosa.load(train_ds.paths[3],sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "933398b4-1d85-4a47-840f-66ce355d7690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63424,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5a00aa1-bf6d-4d49-b21c-2182cd1c6c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67e1ae12-1be0-4693-a0b2-ef80a1d7f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_process(data, sample_rate):\n",
    "    output_result = np.array([])\n",
    "\n",
    "    mean_zero = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    print(mean_zero.shape,librosa.feature.zero_crossing_rate(y=data).shape)\n",
    "    output_result = np.hstack((output_result, mean_zero))\n",
    "\n",
    "    \n",
    "    stft_out = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft_out, sr=sample_rate).T, axis=0)\n",
    "    print(chroma_stft.shape,librosa.feature.chroma_stft(S=stft_out, sr=sample_rate).shape)\n",
    "    output_result = np.hstack((output_result, chroma_stft))\n",
    "\n",
    "    mfcc_out = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    print(mfcc_out.shape,librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).shape)\n",
    "    output_result = np.hstack((output_result, mfcc_out))\n",
    "\n",
    "    root_mean_out = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    print(root_mean_out.shape,librosa.feature.rms(y=data).shape)\n",
    "    output_result = np.hstack((output_result, root_mean_out))\n",
    "\n",
    "    mel_spectogram = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    print(mel_spectogram.shape,librosa.feature.melspectrogram(y=data, sr=sample_rate).shape)\n",
    "    output_result = np.hstack((output_result, mel_spectogram))\n",
    "    \n",
    "\n",
    "    return output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60540fef-ece2-4ff9-b9fd-1287eb3629dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (1, 124)\n",
      "(12,) (12, 124)\n",
      "(40,) (40, 124)\n",
      "(1,) (1, 124)\n",
      "(128,) (128, 124)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(182,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_process(wv,sr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ea38f95-f016-4d8c-9447-6de569046f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7297/1940721832.py:2: UserWarning: Only one segment is calculated since parameter NFFT (=256) >= signal length (=128).\n",
      "  plt.specgram(librosa.feature.melspectrogram(y=wv,sr=sr))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.05541840e+05],\n",
       "        [1.24094435e+05],\n",
       "        [2.44518699e+04],\n",
       "        [2.80540202e+04],\n",
       "        [4.05840230e+04],\n",
       "        [2.71515009e+04],\n",
       "        [1.38767034e+04],\n",
       "        [1.10275500e+04],\n",
       "        [7.62610264e+03],\n",
       "        [3.53166880e+03],\n",
       "        [7.08170111e+03],\n",
       "        [1.75986091e+04],\n",
       "        [2.49137082e+04],\n",
       "        [1.74279306e+04],\n",
       "        [2.03826782e+04],\n",
       "        [3.53168029e+04],\n",
       "        [2.55295583e+04],\n",
       "        [1.08103640e+04],\n",
       "        [1.22223280e+04],\n",
       "        [1.28817461e+04],\n",
       "        [7.81323442e+03],\n",
       "        [7.70999465e+03],\n",
       "        [1.54804888e+04],\n",
       "        [1.30681046e+04],\n",
       "        [5.83418190e+03],\n",
       "        [7.04115194e+03],\n",
       "        [7.12073526e+03],\n",
       "        [3.91133049e+03],\n",
       "        [1.94449661e+03],\n",
       "        [5.05366920e+03],\n",
       "        [6.86791561e+03],\n",
       "        [2.91866759e+03],\n",
       "        [2.06011535e+03],\n",
       "        [3.37566380e+03],\n",
       "        [2.80063970e+03],\n",
       "        [1.43581043e+03],\n",
       "        [4.25968319e+03],\n",
       "        [1.03986970e+04],\n",
       "        [9.02386709e+03],\n",
       "        [4.55681519e+03],\n",
       "        [4.43216868e+03],\n",
       "        [4.45816984e+03],\n",
       "        [4.22764831e+03],\n",
       "        [5.40416914e+03],\n",
       "        [5.46337569e+03],\n",
       "        [2.93087177e+03],\n",
       "        [3.10458219e+03],\n",
       "        [6.12159180e+03],\n",
       "        [6.85640021e+03],\n",
       "        [4.68540338e+03],\n",
       "        [4.30512582e+03],\n",
       "        [1.01183781e+04],\n",
       "        [1.31710371e+04],\n",
       "        [9.60299768e+03],\n",
       "        [8.30787156e+03],\n",
       "        [7.92687010e+03],\n",
       "        [4.98923861e+03],\n",
       "        [3.50643968e+03],\n",
       "        [3.60792249e+03],\n",
       "        [2.67707230e+03],\n",
       "        [1.01692792e+03],\n",
       "        [4.64254079e+02],\n",
       "        [9.20870242e+02],\n",
       "        [1.49525925e+03],\n",
       "        [2.03707430e+03],\n",
       "        [3.76547554e+03],\n",
       "        [6.50694437e+03],\n",
       "        [5.92448724e+03],\n",
       "        [4.37448206e+03],\n",
       "        [5.68326558e+03],\n",
       "        [5.74986836e+03],\n",
       "        [3.43452487e+03],\n",
       "        [2.09551434e+03],\n",
       "        [2.22189578e+03],\n",
       "        [2.19805748e+03],\n",
       "        [1.86120961e+03],\n",
       "        [1.27041507e+03],\n",
       "        [3.93852947e+02],\n",
       "        [8.68413212e+01],\n",
       "        [3.84479089e+02],\n",
       "        [1.08512642e+03],\n",
       "        [1.43851588e+03],\n",
       "        [6.34682491e+02],\n",
       "        [2.76792763e+02],\n",
       "        [1.06175126e+03],\n",
       "        [1.54058843e+03],\n",
       "        [1.17580658e+03],\n",
       "        [5.20904590e+02],\n",
       "        [3.79732341e+02],\n",
       "        [1.13633017e+03],\n",
       "        [1.71247591e+03],\n",
       "        [1.06237870e+03],\n",
       "        [4.49864528e+02],\n",
       "        [1.06901597e+03],\n",
       "        [1.90552182e+03],\n",
       "        [1.72840915e+03],\n",
       "        [9.77483908e+02],\n",
       "        [7.30025031e+02],\n",
       "        [7.49753063e+02],\n",
       "        [6.48103278e+02],\n",
       "        [5.56581516e+02],\n",
       "        [4.38333831e+02],\n",
       "        [3.10183022e+02],\n",
       "        [3.14354231e+02],\n",
       "        [7.98288330e+02],\n",
       "        [1.22742022e+03],\n",
       "        [1.01413159e+03],\n",
       "        [9.58758136e+02],\n",
       "        [1.25132828e+03],\n",
       "        [1.15086811e+03],\n",
       "        [8.19159621e+02],\n",
       "        [1.13139955e+03],\n",
       "        [1.52303933e+03],\n",
       "        [1.01676024e+03],\n",
       "        [5.69095983e+02],\n",
       "        [5.88237955e+02],\n",
       "        [4.78243319e+02],\n",
       "        [3.05927041e+02],\n",
       "        [3.26667845e+02],\n",
       "        [5.39673734e+02],\n",
       "        [5.04124991e+02],\n",
       "        [4.03176028e+02],\n",
       "        [6.22380441e+02],\n",
       "        [7.08346405e+02],\n",
       "        [4.78108755e+02],\n",
       "        [3.10499522e+02],\n",
       "        [5.76593965e+02],\n",
       "        [1.01942409e+03],\n",
       "        [5.91081039e+02]]),\n",
       " array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "        0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "        0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "        0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "        0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "        0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "        0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "        0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "        0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "        0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "        0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "        0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "        0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "        0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "        0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "        0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "        0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "        0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "        0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "        0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "        0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "        0.984375 , 0.9921875, 1.       ]),\n",
       " array([64.]),\n",
       " <matplotlib.image.AxesImage at 0x7f1c65395610>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.specgram(librosa.feature.melspectrogram(y=wv,sr=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99f154ee-73b1-4d8b-bb7f-7705aa09647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it,\n",
    "    and extracts several audio features including mean values of MFCC, Zero Crossing Rate,\n",
    "    Chromagram, Root Mean Square Energy, and Mel Spectrogram from the original and its augmented versions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the original audio file\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=42, offset=0.6)\n",
    "\n",
    "        # Extract features from the original audio data\n",
    "        extracted_features = extract_process(audio, sample_rate)\n",
    "        result = np.array(extracted_features)\n",
    "\n",
    "        # Add noise and extract features\n",
    "        noise_out = add_noise(audio)\n",
    "        output_2 = extract_process(noise_out, sample_rate)\n",
    "        result = np.vstack((result, output_2))\n",
    "\n",
    "        # Time-stretch and then pitch-shift before extracting features\n",
    "        new_out = stretch_process(audio,0.8)\n",
    "        stretch_pitch = pitch_process(new_out, sample_rate,pitch_factor=0.7)\n",
    "        output_3 = extract_process(stretch_pitch, sample_rate)\n",
    "        result = np.vstack((result, output_3))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        print(\"Error Details:\", e)\n",
    "        return None\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b559bf7-94bc-4902-9b59-bfcf017401bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while parsing file:  ../Sound_Classification/archive/respiratory_sound_database//Respiratory_Sound_Database//audio_and_txt_files/101_1b1_Al_sc_Meditron.wav\n",
      "Error Details: No module named 'resampy'\n",
      "\n",
      "This error is lazily reported, having originally occured in\n",
      "  File /home/moose/miniconda3/envs/torch/lib/python3.11/site-packages/librosa/core/audio.py, line 32, in <module>\n",
      "\n",
      "----> resampy = lazy.load(\"resampy\")\n"
     ]
    }
   ],
   "source": [
    "extract_features(train_ds.paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9de456-7fea-4176-ab8a-f71570240c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
